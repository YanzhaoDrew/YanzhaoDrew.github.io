---
title: "Heterogeneous Federated Learning with Scalable Server Mixture-of-Experts"
collection: publications
category: conferences
permalink: /publication/2025-5-30-paper-FedMoE-number-4.md
excerpt: "Proposed a novel Federated Mixture-of-Experts (Fed-MoE) framework to address the challenges of deploying large models in power-constrained environments. Designed an asymmetric FL mechanism where compact client models are aggregated into a large server-side MoE model, enabling efficient learning from heterogeneous data."
date: 2025-05-30
venue: 'In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)'
paperurl: 'http://YanzhaoDrew.github.io/files/MoE_IJCAI_2025_Cam.pdf'
citation: 'Jingang Jiang*, Yanzhao Chen*, Xiangyang Liu, Haiqi Jiang, and Chenyou Fan. Heterogeneous federated learning with scalable server mixture-of-experts. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), 2025. Co-first authors: Jingang Jiang and Yanzhao Chen.'
---

The contents above will be part of a list of publications, if the user clicks the link for the publication than the contents of section will be rendered as a full page, allowing you to provide more information about the paper for the reader. When publications are displayed as a single page, the contents of the above "citation" field will automatically be included below this section in a smaller font.
